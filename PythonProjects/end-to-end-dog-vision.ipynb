{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "170a21d0",
   "metadata": {},
   "source": [
    "## Using Transfer Learning and TensorFlow 2.0 to Classify Different Dog Breeds\n",
    "Who's that doggy in the window?\n",
    "\n",
    "Dogs are incredible. But have you ever been sitting at a cafe, seen a dog and not known what breed it is? I have. And then someone says, \"it's an English Terrier\" and you think, how did they know that?\n",
    "\n",
    "In this project we're going to be using machine learning to help us identify different breeds of dogs.\n",
    "\n",
    "To do this, we'll be using data from the Kaggle dog breed identification competition. It consists of a collection of 10,000+ labelled images of 120 different dog breeds.\n",
    "\n",
    "This kind of problem is called multi-class image classification. It's multi-class because we're trying to classify mutliple different breeds of dog. If we were only trying to classify dogs versus cats, it would be called binary classification (one thing versus another).\n",
    "\n",
    "Multi-class image classification is an important problem because it's the same kind of technology Tesla uses in their self-driving cars or Airbnb uses in atuomatically adding information to their listings.\n",
    "\n",
    "Since the most important step in a deep learng problem is getting the data ready (turning it into numbers), that's what we're going to start with.\n",
    "\n",
    "We're going to go through the following TensorFlow/Deep Learning workflow:\n",
    "\n",
    "Get data ready (download from Kaggle, store, import).\n",
    "Prepare the data (preprocessing, the 3 sets, X & y).\n",
    "Choose and fit/train a model (TensorFlow Hub, tf.keras.applications, TensorBoard, EarlyStopping).\n",
    "Evaluating a model (making predictions, comparing them with the ground truth labels).\n",
    "Improve the model through experimentation (start with 1000 images, make sure it works, increase the number of images).\n",
    "Save, sharing and reloading your model (once you're happy with the results).\n",
    "For preprocessing our data, we're going to use TensorFlow 2.x. The whole premise here is to get our data into Tensors (arrays of numbers which can be run on GPUs) and then allow a machine learning model to find patterns between them.\n",
    "\n",
    "For our machine learning model, we're going to be using a pretrained deep learning model from TensorFlow Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d0d767",
   "metadata": {},
   "source": [
    "## Getting our workspace ready\n",
    "Before we get started, since we'll be using TensorFlow 2.x and TensorFlow Hub (TensorFlow Hub), let's import them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5347db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3098648758.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TF version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f150db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TF 2.x\n",
    "try:\n",
    "  # %tensorflow_version only exists in Colab\n",
    "  %tensorflow_version 2.x\n",
    "except Exception:\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1efbddc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3166026646.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"TF version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hub version:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69fe390",
   "metadata": {},
   "source": [
    "## Getting data ready\n",
    "Since much of machine learning is getting your data ready to be used with a machine learning model, we'll take extra care getting it setup.\n",
    "\n",
    "There are a few ways we could do this. Many of them are detailed in the Google Colab notebook on I/O (input and output).\n",
    "\n",
    "And because the data we're using is hosted on Kaggle, we could even use the Kaggle API.\n",
    "\n",
    "This is great but what if the data you want to use wasn't on Kaggle?\n",
    "\n",
    "One method is to upload it to your Google Drive, mount your drive in this notebook and import the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f831da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3668367894.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Running this cell will provide you with a token to link your drive to this notebook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/drive'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "# Running this cell will provide you with a token to link your drive to this notebook\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c7c27dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the '-d' parameter as the destination for where the files should go\n",
    "#!unzip \"drive/My Drive/Data/dog-breed-identification.zip\" -d \"drive/My Drive/Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377c6299",
   "metadata": {},
   "source": [
    "## Accessing the data\n",
    "Now the data files we're working with are available on our Google Drive, we can start to check it out.\n",
    "\n",
    "Let's start with labels.csv which contains all of the image ID's and their assosciated dog breed (our data and labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a8089f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'drive/My Drive/Data/labels.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3875870637.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Checkout the labels of our data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlabels_csv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drive/My Drive/Data/labels.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_csv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/My Drive/Data/labels.csv'"
     ]
    }
   ],
   "source": [
    "# Checkout the labels of our data\n",
    "import pandas as pd\n",
    "labels_csv = pd.read_csv(\"drive/My Drive/Data/labels.csv\")\n",
    "print(labels_csv.describe())\n",
    "print(labels_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fd0b29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2916847458.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# How many images are there of each breed?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlabels_csv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"breed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# How many images are there of each breed?\n",
    "labels_csv[\"breed\"].value_counts().plot.bar(figsize=(20, 10));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a944fb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "# Image(\"drive/My Drive/Data/train/000bec180eb18c7604dcecc8fe0dba07.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707affe",
   "metadata": {},
   "source": [
    "## Getting images and their labels\n",
    "Since we've got the image ID's and their labels in a DataFrame (labels_csv), we'll use it to create:\n",
    "\n",
    "A list a filepaths to training images\n",
    "An array of all labels\n",
    "An array of all unique labels\n",
    "We'll only create a list of filepaths to images rather than importing them all to begin with. This is because working with filepaths (strings) is much efficient than working with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac04fb2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1253266068.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create pathnames from image ID's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfilenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"drive/My Drive/Data/train/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels_csv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Check the first 10 filenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_csv' is not defined"
     ]
    }
   ],
   "source": [
    "# Create pathnames from image ID's\n",
    "filenames = [\"drive/My Drive/Data/train/\" + fname + \".jpg\" for fname in labels_csv[\"id\"]]\n",
    "\n",
    "# Check the first 10 filenames\n",
    "filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c29f458",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2251967540.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check whether number of filenames matches number of actual image files\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"drive/My Drive/Data/train/\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Filenames match actual amount of files!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/train/'"
     ]
    }
   ],
   "source": [
    "# Check whether number of filenames matches number of actual image files\n",
    "import os\n",
    "if len(os.listdir(\"drive/My Drive/Data/train/\")) == len(filenames):\n",
    "  print(\"Filenames match actual amount of files!\")\n",
    "else:\n",
    "  print(\"Filenames do not match actual amount of files, check the target directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd0cfdde",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3080646666.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check an image directly from a filepath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m9000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# Check an image directly from a filepath\n",
    "Image(filenames[9000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5999e1da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_csv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/459378006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels_csv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"breed\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# convert labels column to NumPy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_csv' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "labels = labels_csv[\"breed\"].to_numpy() # convert labels column to NumPy array\n",
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eea950f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1589550353.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# See if number of labels matches the number of filenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of labels matches number of filenames!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of labels does not match number of filenames, check data directories.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# See if number of labels matches the number of filenames\n",
    "if len(labels) == len(filenames):\n",
    "  print(\"Number of labels matches number of filenames!\")\n",
    "else:\n",
    "  print(\"Number of labels does not match number of filenames, check data directories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f171bd8b",
   "metadata": {},
   "source": [
    "If it all worked, we should have the same amount of images and labels.\n",
    "\n",
    "Finally, since a machine learning model can't take strings as input (what labels currently is), we'll have to convert our labels to numbers.\n",
    "\n",
    "To begin with, we'll find all of the unique dog breed names.\n",
    "\n",
    "Then we'll go through the list of labels and compare them to unique breeds and create a list of booleans indicating which one is the real label (True) and which ones aren't (False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "348def2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/89689323.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Find the unique label values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0munique_breeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Find the unique label values\n",
    "unique_breeds = np.unique(labels)\n",
    "len(unique_breeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ba65d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2800344070.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example: Turn one label into an array of booleans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0munique_breeds\u001b[0m \u001b[1;31m# use comparison operator to create boolean array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Turn one label into an array of booleans\n",
    "print(labels[0])\n",
    "labels[0] == unique_breeds # use comparison operator to create boolean array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "846770e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/319515869.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Turn every label into a boolean array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mboolean_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mboolean_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Turn every label into a boolean array\n",
    "boolean_labels = [label == np.array(unique_breeds) for label in labels]\n",
    "boolean_labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "206a14a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2941428539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Example: Turning a boolean array into integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# original label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# index where label occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboolean_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# index where label occurs in boolean array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboolean_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# there will be a 1 where the sample label occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "# Example: Turning a boolean array into integers\n",
    "print(labels[0]) # original label\n",
    "print(np.where(unique_breeds == labels[0])[0][0]) # index where label occurs\n",
    "print(boolean_labels[0].argmax()) # index where label occurs in boolean array\n",
    "print(boolean_labels[0].astype(int)) # there will be a 1 where the sample label occurs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b45deb",
   "metadata": {},
   "source": [
    "## Creating our own validation set\n",
    "Since the dataset from Kaggle doesn't come with a validation set (a split of the data we can test our model on before making final predicitons on the test set), let's make one.\n",
    "\n",
    "We could use Scikit-Learn's train_test_split function or we could simply make manual splits of the data.\n",
    "\n",
    "For accessibility later, let's save our filenames variable to X (data) and our labels to y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9bab72b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1237408249.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Setup X & y variables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboolean_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup X & y variables\n",
    "X = filenames\n",
    "y = boolean_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de31afdc",
   "metadata": {},
   "source": [
    "Since we're working with 10,000+ images, it's a good idea to work with a portion of them to make sure things are working before training on them all.\n",
    "\n",
    "This is because computing with 10,000+ images could take a fairly long time. And our goal when working through machine learning projects is to reduce the time between experiments.\n",
    "\n",
    "Let's start experimenting with 1000 and increase it as we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae86f051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set number of images to use for experimenting\n",
    "NUM_IMAGES = 1000 #@param {type:\"slider\", min:1000, max:10000, step:1000}\n",
    "NUM_IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4951d94",
   "metadata": {},
   "source": [
    "Now let's split our data into training and validation sets. We'll use and 80/20 split (80% training data, 20% validation data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "161581aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/4028520359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Split them into training and validation using NUM_IMAGES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n\u001b[0m\u001b[0;32m      6\u001b[0m                                                   \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mNUM_IMAGES\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                                   \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Import train_test_split from Scikit-Learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split them into training and validation using NUM_IMAGES \n",
    "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
    "                                                  y[:NUM_IMAGES], \n",
    "                                                  test_size=0.2,\n",
    "                                                  random_state=42)\n",
    "\n",
    "len(X_train), len(y_train), len(X_val), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6267999",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/704950408.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check out the training data (image file paths and labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out the training data (image file paths and labels)\n",
    "X_train[:5], y_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0d34a2",
   "metadata": {},
   "source": [
    "Preprocessing images (turning images into Tensors)\n",
    "Our labels are in numeric format but our images are still just file paths.\n",
    "\n",
    "Since we're using TensorFlow, our data has to be in the form of Tensors.\n",
    "\n",
    "A Tensor is a way to represent information in numbers. If you're familar with NumPy arrays (you should be), a Tensor can be thought of as a combination of NumPy arrays, except with the special ability to be used on a GPU.\n",
    "\n",
    "Because of how TensorFlow stores information (in Tensors), it allows machine learning and deep learning models to be run on GPUs (generally faster at numerical computing).\n",
    "\n",
    "To preprocess our images into Tensors we're going to write a function which does a few things:\n",
    "\n",
    "Takes an image filename as input.\n",
    "Uses TensorFlow to read the file and save it to a variable, image.\n",
    "Turn our image (a jpeg file) into Tensors.\n",
    "Resize the image to be of shape (224, 224).\n",
    "Return the modified image.\n",
    "A good place to read about this type of function is the TensorFlow documentation on loading images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "753299df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1968933019.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Convert image to NumPy array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# read in an image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert image to NumPy array\n",
    "from matplotlib.pyplot import imread\n",
    "image = imread(filenames[42]) # read in an image\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "963bdee7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1511907891.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.constant(image)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0744d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image size\n",
    "IMG_SIZE = 224\n",
    "\n",
    "def process_image(image_path):\n",
    "  \"\"\"\n",
    "  Takes an image file path and turns it into a Tensor.\n",
    "  \"\"\"\n",
    "  # Read in image file\n",
    "  image = tf.io.read_file(image_path)\n",
    "  # Turn the jpeg image into numerical Tensor with 3 colour channels (Red, Green, Blue)\n",
    "  image = tf.image.decode_jpeg(image, channels=3)\n",
    "  # Convert the colour channel values from 0-225 values to 0-1 values\n",
    "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "  # Resize the image to our desired size (224, 244)\n",
    "  image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0436b69",
   "metadata": {},
   "source": [
    "## Creating data batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed17e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple function to return a tuple (image, label)\n",
    "def get_image_label(image_path, label):\n",
    "  \"\"\"\n",
    "  Takes an image file path name and the associated label,\n",
    "  processes the image and returns a tuple of (image, label).\n",
    "  \"\"\"\n",
    "  image = process_image(image_path)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebc7416",
   "metadata": {},
   "source": [
    "Now we've got a simple function to turn our image file path names and their associated labels into tuples (we can turn these into Tensors next), we'll create a function to make data batches.\n",
    "\n",
    "Because we'll be dealing with 3 different sets of data (training, validation and test), we'll make sure the function can accomodate for each set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88507576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the batch size, 32 is a good default\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create a function to turn data into batches\n",
    "def create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n",
    "  \"\"\"\n",
    "  Creates batches of data out of image (x) and label (y) pairs.\n",
    "  Shuffles the data if it's training data but doesn't shuffle it if it's validation data.\n",
    "  Also accepts test data as input (no labels).\n",
    "  \"\"\"\n",
    "  # If the data is a test dataset, we probably don't have labels\n",
    "  if test_data:\n",
    "    print(\"Creating test data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x))) # only filepaths\n",
    "    data_batch = data.map(process_image).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "  \n",
    "  # If the data if a valid dataset, we don't need to shuffle it\n",
    "  elif valid_data:\n",
    "    print(\"Creating validation data batches...\")\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
    "                                               tf.constant(y))) # labels\n",
    "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
    "    return data_batch\n",
    "\n",
    "  else:\n",
    "    # If the data is a training dataset, we shuffle it\n",
    "    print(\"Creating training data batches...\")\n",
    "    # Turn filepaths and labels into Tensors\n",
    "    data = tf.data.Dataset.from_tensor_slices((tf.constant(x), # filepaths\n",
    "                                              tf.constant(y))) # labels\n",
    "    \n",
    "    # Shuffling pathnames and labels before mapping image processor function is faster than shuffling images\n",
    "    data = data.shuffle(buffer_size=len(x))\n",
    "\n",
    "    # Create (image, label) tuples (this also turns the image path into a preprocessed image)\n",
    "    data = data.map(get_image_label)\n",
    "\n",
    "    # Turn the data into batches\n",
    "    data_batch = data.batch(BATCH_SIZE)\n",
    "  return data_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea55c2ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3745168741.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create training and validation data batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Create training and validation data batches\n",
    "train_data = create_data_batches(X_train, y_train)\n",
    "val_data = create_data_batches(X_val, y_val, valid_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03231907",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/947339270.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check out the different attributes of our data batches\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out the different attributes of our data batches\n",
    "train_data.element_spec, val_data.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed354f67",
   "metadata": {},
   "source": [
    "## Visualizing data batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63432169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a function for viewing images in a data batch\n",
    "def show_25_images(images, labels):\n",
    "  \"\"\"\n",
    "  Displays 25 images from a data batch.\n",
    "  \"\"\"\n",
    "  # Setup the figure\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  # Loop through 25 (for displaying 25 images)\n",
    "  for i in range(25):\n",
    "    # Create subplots (5 rows, 5 columns)\n",
    "    ax = plt.subplot(5, 5, i+1)\n",
    "    # Display an image\n",
    "    plt.imshow(images[i])\n",
    "    # Add the image label as the title\n",
    "    plt.title(unique_breeds[labels[i].argmax()])\n",
    "    # Turn gird lines off\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ebf9e00",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/4126820407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize training images from the training data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mshow_25_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize training images from the training data batch\n",
    "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
    "show_25_images(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8cff5b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/346564568.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Visualize validation images from the validation data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mshow_25_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize validation images from the validation data batch\n",
    "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
    "show_25_images(val_images, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdcd3a",
   "metadata": {},
   "source": [
    "## Creating and training a model\n",
    "Now our data is ready, let's prepare it modelling. We'll use an existing model from TensorFlow Hub.\n",
    "\n",
    "TensorFlow Hub is a resource where you can find pretrained machine learning models for the problem you're working on.\n",
    "\n",
    "Using a pretrained machine learning model is often referred to as transfer learning.\n",
    "\n",
    "Why use a pretrained model?\n",
    "Building a machine learning model and training it on lots from scratch can be expensive and time consuming.\n",
    "\n",
    "Transfer learning helps eliviate some of these by taking what another model has learned and using that information with your own problem.\n",
    "\n",
    "How do we choose a model?\n",
    "Since we know our problem is image classification (classifying different dog breeds), we can navigate the TensorFlow Hub page by our problem domain (image).\n",
    "\n",
    "We start by choosing the image problem domain, and then can filter it down by subdomains, in our case, image classification.\n",
    "\n",
    "Doing this gives a list of different pretrained models we can apply to our task.\n",
    "\n",
    "Clicking on one gives us information about the model as well as instructions for using it.\n",
    "\n",
    "For example, clicking on the mobilenet_v2_130_224 model, tells us this model takes an input of images in the shape 224, 224. It also says the model has been trained in the domain of image classification.\n",
    "\n",
    "Let's try it out.\n",
    "\n",
    "Building a model\n",
    "Before we build a model, there are a few things we need to define:\n",
    "\n",
    "The input shape (images, in the form of Tensors) to our model.\n",
    "The output shape (image labels, in the form of Tensors) of our model.\n",
    "The URL of the model we want to use.\n",
    "These things will be standard practice with whatever machine learning model you use. And because we're using TensorFlow, everything will be in the form of Tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7be799c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_breeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/980709108.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Setup output shape of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mOUTPUT_SHAPE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# number of unique labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Setup model URL from TensorFlow Hub\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_breeds' is not defined"
     ]
    }
   ],
   "source": [
    "# Setup input shape to the model\n",
    "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] # batch, height, width, colour channels\n",
    "\n",
    "# Setup output shape of the model\n",
    "OUTPUT_SHAPE = len(unique_breeds) # number of unique labels\n",
    "\n",
    "# Setup model URL from TensorFlow Hub\n",
    "MODEL_URL = \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/classification/4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94b0108",
   "metadata": {},
   "source": [
    "Now we've got the inputs, outputs and model we're using ready to go. We can start to put them together\n",
    "\n",
    "There are many ways of building a model in TensorFlow but one of the best ways to get started is to use the Keras API.\n",
    "\n",
    "Defining a deep learning model in Keras can be as straightforward as saying, \"here are the layers of the model, the input shape and the output shape, let's go!\"\n",
    "\n",
    "Knowing this, let's create a function which:\n",
    "\n",
    "Takes the input shape, output shape and the model we've chosen's URL as parameters.\n",
    "Defines the layers in a Keras model in a sequential fashion (do this first, then this, then that).\n",
    "Compiles the model (says how it should be evaluated and improved).\n",
    "Builds the model (tells it what kind of input shape it'll be getting).\n",
    "Returns the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5d7ff301",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OUTPUT_SHAPE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1650486546.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a function which builds a Keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mINPUT_SHAPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mOUTPUT_SHAPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_url\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMODEL_URL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Building model with:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_URL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;31m# Setup the model layers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OUTPUT_SHAPE' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a function which builds a Keras model\n",
    "def create_model(input_shape=INPUT_SHAPE, output_shape=OUTPUT_SHAPE, model_url=MODEL_URL):\n",
    "  print(\"Building model with:\", MODEL_URL)\n",
    "\n",
    "  # Setup the model layers\n",
    "  model = tf.keras.Sequential([\n",
    "    hub.KerasLayer(MODEL_URL), # Layer 1 (input layer)\n",
    "    tf.keras.layers.Dense(units=OUTPUT_SHAPE, \n",
    "                          activation=\"softmax\") # Layer 2 (output layer)\n",
    "  ])\n",
    "\n",
    "  # Compile the model\n",
    "  model.compile(\n",
    "      loss=tf.keras.losses.CategoricalCrossentropy(), # Our model wants to reduce this (how wrong its guesses are)\n",
    "      optimizer=tf.keras.optimizers.Adam(), # A friend telling our model how to improve its guesses\n",
    "      metrics=[\"accuracy\"] # We'd like this to go up\n",
    "  )\n",
    "\n",
    "  # Build the model\n",
    "  model.build(INPUT_SHAPE) # Let the model know what kind of inputs it'll be getting\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6247fe77",
   "metadata": {},
   "source": [
    "## Setting up the model layers\n",
    "There are two ways to do this in Keras, the functional and sequential API. We've used the sequential.\n",
    "\n",
    "Which one should you use?\n",
    "\n",
    "The Keras documentation states the functional API is the way to go for defining complex models but the sequential API (a linear stack of layers) is perfectly fine for getting started, which is what we're doing.\n",
    "\n",
    "The first layer we use is the model from TensorFlow Hub (hub.KerasLayer(MODEL_URL). So our first layer is actually an entire model (many more layers). This input layer takes in our images and finds patterns in them based on the patterns mobilenet_v2_130_224 has found.\n",
    "\n",
    "The next layer (tf.keras.layers.Dense()) is the output layer of our model. It brings all of the information discovered in the input layer together and outputs it in the shape we're after, 120 (the number of unique labels we have).\n",
    "\n",
    "The activation=\"softmax\" parameter tells the output layer, we'd like to assign a probability value to each of the 120 labels somewhere between 0 & 1. The higher the value, the more the model believes the input image should have that label. If we were working on a binary classification problem, we'd use activation=\"sigmoid\".\n",
    "\n",
    "For more on which activation function to use, see the article Which Loss and Activation Functions Should I Use?\n",
    "\n",
    "## Compiling the model\n",
    "This one is best explained with a story.\n",
    "\n",
    "Let's say you're at the international hill descending championships. Where your start standing on top of a hill and your goal is to get to the bottom of the hill. The catch is you're blindfolded.\n",
    "\n",
    "Luckily, your friend Adam is standing at the bottom of the hill shouting instructions on how to get down.\n",
    "\n",
    "At the bottom of the hill there's a judge evaluating how you're doing. They know where you need to end up so they compare how you're doing to where you're supposed to be. Their comparison is how you get scored.\n",
    "\n",
    "Transferring this to model.compile() terminology:\n",
    "\n",
    "loss - The height of the hill is the loss function, the models goal is to minimize this, getting to 0 (the bottom of the hill) means the model is learning perfectly.\n",
    "optimizer - Your friend Adam is the optimizer, he's the one telling you how to navigate the hill (lower the loss function) based on what you've done so far. His name is Adam because the Adam optimizer is a great general which performs well on most models. Other optimizers include RMSprop and Stochastic Gradient Descent.\n",
    "metrics - This is the onlooker at the bottom of the hill rating how well your perfomance is. Or in our case, giving the accuracy of how well our model is predicting the correct image label.\n",
    "## Building the model\n",
    "We use model.build() whenever we're using a layer from TensorFlow Hub to tell our model what input shape it can expect.\n",
    "\n",
    "In this case, the input shape is [None, IMG_SIZE, IMG_SIZE, 3] or [None, 224, 224, 3] or [batch_size, img_height, img_width, color_channels].\n",
    "\n",
    "Batch size is left as None as this is inferred from the data we pass the model. In our case, it'll be 32 since that's what we've set up our data batches as.\n",
    "\n",
    "Now we've gone through each section of the function, let's use it to create a model.\n",
    "\n",
    "We can call summary() on our model to get idea of what our model looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3bf2cee0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3471971573.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create a model and check its details\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a model and check its details\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d723f649",
   "metadata": {},
   "source": [
    "The non-trainable parameters are the patterns learned by mobilenet_v2_130_224 and the trainable parameters are the ones in the dense layer we added.\n",
    "\n",
    "This means the main bulk of the information in our model has already been learned and we're going to take that and adapt it to our own problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4149704a",
   "metadata": {},
   "source": [
    "Creating callbacks\n",
    "We've got a model ready to go but before we train it we'll make some callbacks.\n",
    "\n",
    "Callbacks are helper functions a model can use during training to do things such as save a models progress, check a models progress or stop training early if a model stops improving.\n",
    "\n",
    "The two callbacks we're going to add are a TensorBoard callback and an Early Stopping callback.\n",
    "\n",
    "TensorBoard Callback\n",
    "TensorBoard helps provide a visual way to monitor the progress of your model during and after training.\n",
    "\n",
    "It can be used directly in a notebook to track the performance measures of a model such as loss and accuracy.\n",
    "\n",
    "To set up a TensorBoard callback and view TensorBoard in a notebook, we need to do three things:\n",
    "\n",
    "Load the TensorBoard notebook extension.\n",
    "Create a TensorBoard callback which is able to save logs to a directory and pass it to our model's fit() function.\n",
    "Visualize the our models training logs using the %tensorboard magic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "504b7911",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/164852851.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the TensorBoard notebook extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'load_ext'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tensorboard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2349\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2351\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2352\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\IPython\\core\\magics\\extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Missing module name.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'already loaded'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\site-packages\\IPython\\core\\extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmodule_str\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mprepended_to_syspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m                     \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mipython_extension_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m                         print((\"Loading extensions from {dir} is deprecated. \"\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\importlib\\__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\A3\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "941e5d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Create a function to build a TensorBoard callback\n",
    "def create_tensorboard_callback():\n",
    "  # Create a log directory for storing TensorBoard logs\n",
    "  logdir = os.path.join(\"drive/My Drive/Data/logs\",\n",
    "                        # Make it so the logs get tracked whenever we run an experiment\n",
    "                        datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "  return tf.keras.callbacks.TensorBoard(logdir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba666a",
   "metadata": {},
   "source": [
    "Early Stopping Callback\n",
    "Early stopping helps prevent overfitting by stopping a model when a certain evaluation metric stops improving. If a model trains for too long, it can do so well at finding patterns in a certain dataset that it's not able to use those patterns on another dataset it hasn't seen before (doesn't generalize).\n",
    "\n",
    "It's basically like saying to our model, \"keep finding patterns until the quality of those patterns starts to go down."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc05bb5",
   "metadata": {},
   "source": [
    "## Training a model (on a subset of data)\n",
    "Our first model is only going to be trained on 1000 images. Or trained on 800 images and then validated on 200 images, meaning 1000 images total or about 10% of the total data.\n",
    "\n",
    "We do this to make sure everything is working. And if it is, we can step it up later and train on the entire training dataset.\n",
    "\n",
    "The final parameter we'll define before training is NUM_EPOCHS (also known as number of epochs).\n",
    "\n",
    "NUM_EPOCHS defines how many passes of the data we'd like our model to do. A pass is equivalent to our model trying to find patterns in each dog image and see which patterns relate to each label.\n",
    "\n",
    "If NUM_EPOCHS=1, the model will only look at the data once and will probably score badly because it hasn't a chance to correct itself. It would be like you competing in the international hill descent championships and your friend Adam only being able to give you 1 single instruction to get down the hill.\n",
    "\n",
    "What's a good value for NUM_EPOCHS?\n",
    "\n",
    "This one is hard to say. 10 could be a good start but so could 100. This is one of the reasons we created an early stopping callback. Having early stopping setup means if we set NUM_EPOCHS to 100 but our model stops improving after 22 epochs, it'll stop training.\n",
    "\n",
    "Along with this, let's quickly check if we're still using a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91dbf654",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_20216/1134020930.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\George\\AppData\\Local\\Temp/ipykernel_20216/1134020930.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not av\u001b[0m\n\u001b[1;37m                                                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Check again if GPU is available (otherwise computing will take a looooonnnnggggg time)\n",
    "print(\"GPU\", \"available (YESS!!!!)\" if tf.config.list_physical_devices(\"GPU\") else \"not av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "911b3b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many rounds should we get the model to look through the data?\n",
    "NUM_EPOCHS = 100 #@param {type:\"slider\", min:10, max:100, step:10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a32b57f",
   "metadata": {},
   "source": [
    "Boom! We've got a GPU running and NUM_EPOCHS setup. Let's create a simple function which trains a model. The function will:\n",
    "\n",
    "Create a model using create_model().\n",
    "Setup a TensorBoard callback using create_tensorboard_callback() (we do this here so it creates a log directory of the current date and time).\n",
    "Call the fit() function on our model passing it the training data, validatation data, number of epochs to train for and the callbacks we'd like to use.\n",
    "Return the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59ccaa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a function to train and return a trained model\n",
    "def train_model():\n",
    "  \"\"\"\n",
    "  Trains a given model and returns the trained version.\n",
    "  \"\"\"\n",
    "  # Create a model\n",
    "  model = create_model()\n",
    "\n",
    "  # Create new TensorBoard session everytime we train a model\n",
    "  tensorboard = create_tensorboard_callback()\n",
    "\n",
    "  # Fit the model to the data passing it the callbacks we created\n",
    "  model.fit(x=train_data,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            validation_data=val_data,\n",
    "            validation_freq=1, # check validation metrics every epoch\n",
    "            callbacks=[tensorboard, early_stopping])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2833c30c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/576529605.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model to the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2467948807.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m   \"\"\"\n\u001b[0;32m      6\u001b[0m   \u001b[1;31m# Create a model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m   \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;31m# Create new TensorBoard session everytime we train a model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the model to the data\n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686501c3",
   "metadata": {},
   "source": [
    "## Checking the TensorBoard logs\n",
    "Now our model has been trained, we can make its performance visual by checking the TensorBoard logs.\n",
    "\n",
    "The TensorBoard magic function (%tensorboard) will access the logs directory we created earlier and viualize its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "78fece3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir drive/My\\ Drive/Data/logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3b413",
   "metadata": {},
   "source": [
    "Thanks to our early_stopping callback, the model stopped training after 26 or so epochs (in my case, yours might be slightly different). This is because the validation accuracy failed to improve for 3 epochs.\n",
    "\n",
    "But the good new is, we can definitely see our model is learning something. The validation accuracy got to 65% in only a few minutes.\n",
    "\n",
    "This means, if we were to scale up the number of images, hopefully we'd see the accuracy increase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cba3c3",
   "metadata": {},
   "source": [
    "## Making and evaluating predictions using a trained model\n",
    "Before we scale up and train on more data, let's see some other ways we can evaluate our model. Because although accuracy is a pretty good indicator of how our model is doing, it would be even better if we could could see it in action.\n",
    "\n",
    "Making predictions with a trained model is as calling predict() on it and passing it data in the same format the model was trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7563bec3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/200576721.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions on the validation data (not used to train on)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# verbose shows us how long there is to go\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions on the validation data (not used to train on)\n",
    "predictions = model.predict(val_data, verbose=1) # verbose shows us how long there is to go\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8550a02a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/356127849.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check the shape of predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Check the shape of predictions\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ced163",
   "metadata": {},
   "source": [
    "Making predictions with our model returns an array with a different value for each label.\n",
    "\n",
    "In this case, making predictions on the validation data (200 images) returns an array (predictions) of arrays, each containing 120 different values (one for each unique dog breed).\n",
    "\n",
    "These different values are the probabilities or the likelihood the model has predicted a certain image being a certain breed of dog. The higher the value, the more likely the model thinks a given image is a specific breed of dog.\n",
    "\n",
    "Let's see how we'd convert an array of probabilities into an actual label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "97f255ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/564692400.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# First prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Max value (probability of prediction): {np.max(predictions[0])}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# the max probability value predicted by the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Sum: {np.sum(predictions[0])}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# because we used softmax activation in our model, this will be close to 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Max index: {np.argmax(predictions[0])}\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# the index of where the max value in predictions[0] occurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# First prediction\n",
    "print(predictions[0])\n",
    "print(f\"Max value (probability of prediction): {np.max(predictions[0])}\") # the max probability value predicted by the model\n",
    "print(f\"Sum: {np.sum(predictions[0])}\") # because we used softmax activation in our model, this will be close to 1\n",
    "print(f\"Max index: {np.argmax(predictions[0])}\") # the index of where the max value in predictions[0] occurs\n",
    "print(f\"Predicted label: {unique_breeds[np.argmax(predictions[0])]}\") # the predicted l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03861ca0",
   "metadata": {},
   "source": [
    "Having this information is great but it would be even better if we could compare a prediction to its true label and original image.\n",
    "\n",
    "To help us, let's first build a little function to convert prediction probabilities into predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76ce8451",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1871164505.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Get a predicted label based on an array of prediction probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mpred_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_pred_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mpred_label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Turn prediction probabilities into their respective label (easier to understand)\n",
    "def get_pred_label(prediction_probabilities):\n",
    "  \"\"\"\n",
    "  Turns an array of prediction probabilities into a label.\n",
    "  \"\"\"\n",
    "  return unique_breeds[np.argmax(prediction_probabilities)]\n",
    "\n",
    "# Get a predicted label based on an array of prediction probabilities\n",
    "pred_label = get_pred_label(predictions[0])\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ec2b4",
   "metadata": {},
   "source": [
    "Since our validation data (val_data) is in batch form, to get a list of validation images and labels, we'll have to unbatch it (using unbatch()) and then turn it into an iterator using as_numpy_iterator().\n",
    "\n",
    "Let's make a small function to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57cb2af2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1475830712.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Unbatchify the validation data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munbatchify\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[0mval_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a function to unbatch a batched dataset\n",
    "def unbatchify(data):\n",
    "  \"\"\"\n",
    "  Takes a batched dataset of (image, label) Tensors and returns separate arrays\n",
    "  of images and labels.\n",
    "  \"\"\"\n",
    "  images = []\n",
    "  labels = []\n",
    "  # Loop through unbatched data\n",
    "  for image, label in data.unbatch().as_numpy_iterator():\n",
    "    images.append(image)\n",
    "    labels.append(unique_breeds[np.argmax(label)])\n",
    "  return images, labels\n",
    "\n",
    "# Unbatchify the validation data\n",
    "val_images, val_labels = unbatchify(val_data)\n",
    "val_images[0], val_labels[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f746dd57",
   "metadata": {},
   "source": [
    "Now we've got ways to get:\n",
    "\n",
    "Prediction labels\n",
    "Validation labels (truth labels)\n",
    "Validation images\n",
    "Let's make some functions to make these all a bit more visualize.\n",
    "\n",
    "More specifically, we want to be able to view an image, its predicted label and its actual label (true label).\n",
    "\n",
    "The first function we'll create will:\n",
    "\n",
    "Take an array of prediction probabilities, an array of truth labels, an array of images and an integer.\n",
    "Convert the prediction probabilities to a predicted label.\n",
    "Plot the predicted label, its predicted probability, the truth label and target image on a single plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bd3599f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(prediction_probabilities, labels, images, n=1):\n",
    "  \"\"\"\n",
    "  View the prediction, ground truth label and image for sample n.\n",
    "  \"\"\"\n",
    "  pred_prob, true_label, image = prediction_probabilities[n], labels[n], images[n]\n",
    "  \n",
    "  # Get the pred label\n",
    "  pred_label = get_pred_label(pred_prob)\n",
    "  \n",
    "  # Plot image & remove ticks\n",
    "  plt.imshow(image)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  # Change the color of the title depending on if the prediction is right or wrong\n",
    "  if pred_label == true_label:\n",
    "    color = \"green\"\n",
    "  else:\n",
    "    color = \"red\"\n",
    "\n",
    "  plt.title(\"{} {:2.0f}% ({})\".format(pred_label,\n",
    "                                      np.max(pred_prob)*100,\n",
    "                                      true_label),\n",
    "                                      color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f5980388",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1467487121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# View an example prediction, original image and truth label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m plot_pred(prediction_probabilities=predictions,\n\u001b[0m\u001b[0;32m      3\u001b[0m           \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m           images=val_images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# View an example prediction, original image and truth label\n",
    "plot_pred(prediction_probabilities=predictions,\n",
    "          labels=val_labels,\n",
    "          images=val_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124e79b",
   "metadata": {},
   "source": [
    "Since we're working with a multi-class problem (120 different dog breeds), it would also be good to see what other guesses our model is making. More specifically, if our model predicts a certain label with 24% probability, what else did it predict?\n",
    "\n",
    "Let's build a function to demonstrate. The function will:\n",
    "\n",
    "Take an input of a prediction probabilities array, a ground truth labels array and an integer.\n",
    "Find the predicted label using get_pred_label().\n",
    "Find the top 10:\n",
    "Prediction probabilities indexes\n",
    "Prediction probabilities values\n",
    "Prediction labels\n",
    "Plot the top 10 prediction probability values and labels, coloring the true label green."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b99a761",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_conf(prediction_probabilities, labels, n=1):\n",
    "  \"\"\"\n",
    "  Plots the top 10 highest prediction confidences along with\n",
    "  the truth label for sample n.\n",
    "  \"\"\"\n",
    "  pred_prob, true_label = prediction_probabilities[n], labels[n]\n",
    "\n",
    "  # Get the predicted label\n",
    "  pred_label = get_pred_label(pred_prob)\n",
    "\n",
    "  # Find the top 10 prediction confidence indexes\n",
    "  top_10_pred_indexes = pred_prob.argsort()[-10:][::-1]\n",
    "  # Find the top 10 prediction confidence values\n",
    "  top_10_pred_values = pred_prob[top_10_pred_indexes]\n",
    "  # Find the top 10 prediction labels\n",
    "  top_10_pred_labels = unique_breeds[top_10_pred_indexes]\n",
    "\n",
    "  # Setup plot\n",
    "  top_plot = plt.bar(np.arange(len(top_10_pred_labels)), \n",
    "                     top_10_pred_values, \n",
    "                     color=\"grey\")\n",
    "  plt.xticks(np.arange(len(top_10_pred_labels)),\n",
    "             labels=top_10_pred_labels,\n",
    "             rotation=\"vertical\")\n",
    "\n",
    "  # Change color of true label\n",
    "  if np.isin(true_label, top_10_pred_labels):\n",
    "    top_plot[np.argmax(top_10_pred_labels == true_label)].set_color(\"green\")\n",
    "  else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b11acbb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1593929094.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m plot_pred_conf(prediction_probabilities=predictions,\n\u001b[0m\u001b[0;32m      2\u001b[0m                \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                n=9)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "plot_pred_conf(prediction_probabilities=predictions,\n",
    "               labels=val_labels,\n",
    "               n=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d25aa7",
   "metadata": {},
   "source": [
    "Wonderful! Now we've got some functions to help us visualize our predictions and evaluate our model, let's check out a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "05e196f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2612290456.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m   plot_pred(prediction_probabilities=predictions,\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mimages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAASAAAAETCAYAAACWbduDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAANFElEQVR4nO3cf6jdd33H8edriQGtzhYbxeUHy0a0ZsMOe+1E3FYnm0n3RxD6R1tZWRFCwYp/tuwPHfSf+cdApNUQSij+Y/6xuDiiZWxoBzXaG+ivtLTcRdZeIzRVcaCwkva9P87Zdjy7yf3m5ty87z15PuDC/X7P557z/nJ7nvme7z2nqSokqcNvdQ8g6eplgCS1MUCS2hggSW0MkKQ2BkhSm1UDlORokleTPHeB25PkK0mWkjyT5EOzH1PSPBpyBvQIsP8itx8A9o6/DgFfu/yxJF0NVg1QVT0O/PwiSw4CX6+Rk8C1Sd47qwElza9ZXAPaAbwysb083idJF7V1BveRFfat+PmOJIcYvUzjmmuuuemGG26YwcNL6nTq1KnXqmr7Wn52FgFaBnZNbO8Ezq60sKqOAEcAFhYWanFxcQYPL6lTkv9Y68/O4iXYceCu8V/DPgL8sqp+OoP7lTTnVj0DSvIN4Bbg+iTLwBeBtwBU1WHgBHArsAT8Grh7vYaVNF9WDVBV3bHK7QV8dmYTSbpq+E5oSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUZFKAk+5O8mGQpyf0r3P7OJN9O8nSS00nunv2okubNqgFKsgV4CDgA7APuSLJvatlngeer6kbgFuAfkmyb8ayS5syQM6CbgaWqOlNVrwPHgINTawp4R5IAbwd+Dpyf6aSS5s6QAO0AXpnYXh7vm/Qg8AHgLPAs8PmqenMmE0qaW0MClBX21dT2J4GngN8B/gh4MMlv/787Sg4lWUyyeO7cuUscVdK8GRKgZWDXxPZORmc6k+4GHq2RJeDHwA3Td1RVR6pqoaoWtm/fvtaZJc2JIQF6EtibZM/4wvLtwPGpNS8DnwBI8h7g/cCZWQ4qaf5sXW1BVZ1Pci/wGLAFOFpVp5PcM779MPAA8EiSZxm9ZLuvql5bx7klzYFVAwRQVSeAE1P7Dk98fxb4y9mOJmne+U5oSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUZFKAk+5O8mGQpyf0XWHNLkqeSnE7y/dmOKWkebV1tQZItwEPAXwDLwJNJjlfV8xNrrgW+CuyvqpeTvHud5pU0R4acAd0MLFXVmap6HTgGHJxacyfwaFW9DFBVr852TEnzaEiAdgCvTGwvj/dNeh9wXZLvJTmV5K5ZDShpfq36EgzICvtqhfu5CfgE8FbgB0lOVtVLv3FHySHgEMDu3bsvfVpJc2XIGdAysGtieydwdoU1362qX1XVa8DjwI3Td1RVR6pqoaoWtm/fvtaZJc2JIQF6EtibZE+SbcDtwPGpNf8I/EmSrUneBvwx8MJsR5U0b1Z9CVZV55PcCzwGbAGOVtXpJPeMbz9cVS8k+S7wDPAm8HBVPbeeg0va/FI1fTnnylhYWKjFxcWWx5Y0O0lOVdXCWn7Wd0JLamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqc2gACXZn+TFJEtJ7r/Iug8neSPJbbMbUdK8WjVASbYADwEHgH3AHUn2XWDdl4DHZj2kpPk05AzoZmCpqs5U1evAMeDgCus+B3wTeHWG80maY0MCtAN4ZWJ7ebzvfyXZAXwKODy70STNuyEBygr7amr7y8B9VfXGRe8oOZRkMcniuXPnBo4oaV5tHbBmGdg1sb0TODu1ZgE4lgTgeuDWJOer6luTi6rqCHAEYGFhYTpikq4yQwL0JLA3yR7gJ8DtwJ2TC6pqz/98n+QR4J+m4yNJ01YNUFWdT3Ivo79ubQGOVtXpJPeMb/e6j6Q1GXIGRFWdAE5M7VsxPFX1N5c/lqSrge+EltTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFKbQQFKsj/Ji0mWkty/wu2fTvLM+OuJJDfOflRJ82bVACXZAjwEHAD2AXck2Te17MfAn1XVB4EHgCOzHlTS/BlyBnQzsFRVZ6rqdeAYcHByQVU9UVW/GG+eBHbOdkxJ82hIgHYAr0xsL4/3XchngO9czlCSrg5bB6zJCvtqxYXJxxkF6GMXuP0QcAhg9+7dA0eUNK+GnAEtA7smtncCZ6cXJfkg8DBwsKp+ttIdVdWRqlqoqoXt27evZV5Jc2RIgJ4E9ibZk2QbcDtwfHJBkt3Ao8BfV9VLsx9T0jxa9SVYVZ1Pci/wGLAFOFpVp5PcM779MPAF4F3AV5MAnK+qhfUbW9I8SNWKl3PW3cLCQi0uLrY8tqTZSXJqrSccvhNaUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0MkKQ2BkhSGwMkqY0BktTGAElqY4AktTFAktoYIEltDJCkNgZIUhsDJKmNAZLUxgBJamOAJLUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWpjgCS1MUCS2hggSW0GBSjJ/iQvJllKcv8KtyfJV8a3P5PkQ7MfVdK8WTVASbYADwEHgH3AHUn2TS07AOwdfx0CvjbjOSXNoSFnQDcDS1V1pqpeB44BB6fWHAS+XiMngWuTvHfGs0qaM0MCtAN4ZWJ7ebzvUtdI0m/YOmBNVthXa1hDkkOMXqIB/FeS5wY8/kZ2PfBa9xCXYbPPD5v/GDb7/ADvX+sPDgnQMrBrYnsncHYNa6iqI8ARgCSLVbVwSdNuMJv9GDb7/LD5j2Gzzw+jY1jrzw55CfYksDfJniTbgNuB41NrjgN3jf8a9hHgl1X107UOJenqsOoZUFWdT3Iv8BiwBThaVaeT3DO+/TBwArgVWAJ+Ddy9fiNLmhdDXoJRVScYRWZy3+GJ7wv47CU+9pFLXL8RbfZj2Ozzw+Y/hs0+P1zGMWTUDkm68vwohqQ26x6gzf4xjgHzf3o89zNJnkhyY8ecF7PaMUys+3CSN5LcdiXnW82Q+ZPckuSpJKeTfP9Kz7iaAf8dvTPJt5M8PT6GDXUdNcnRJK9e6K0za34eV9W6fTG6aP3vwO8B24CngX1Ta24FvsPovUQfAX64njOtw/wfBa4bf39gI80/9Bgm1v0ro2t9t3XPfYm/g2uB54Hd4+13d8+9hmP4W+BL4++3Az8HtnXPPjHfnwIfAp67wO1reh6v9xnQZv8Yx6rzV9UTVfWL8eZJRu+B2kiG/A4APgd8E3j1Sg43wJD57wQeraqXAapqMx5DAe9IEuDtjAJ0/sqOeWFV9TijmS5kTc/j9Q7QZv8Yx6XO9hlG/wpsJKseQ5IdwKeAw2w8Q34H7wOuS/K9JKeS3HXFphtmyDE8CHyA0Rt4nwU+X1VvXpnxZmJNz+NBf4a/DDP7GEeTwbMl+TijAH1sXSe6dEOO4cvAfVX1xugf4A1lyPxbgZuATwBvBX6Q5GRVvbTeww005Bg+CTwF/Dnw+8A/J/m3qvrPdZ5tVtb0PF7vAM3sYxxNBs2W5IPAw8CBqvrZFZptqCHHsAAcG8fneuDWJOer6ltXZMKLG/rf0GtV9SvgV0keB24ENkqAhhzD3cDf1+iCylKSHwM3AD+6MiNetrU9j9f5wtVW4Aywh/+7+PYHU2v+it+8ePWj7gtulzj/bkbvAP9o97xrPYap9Y+wsS5CD/kdfAD4l/HatwHPAX/YPfslHsPXgL8bf/8e4CfA9d2zT834u1z4IvSansfregZUm/xjHAPn/wLwLuCr4zOI87WBPlw48Bg2rCHzV9ULSb4LPAO8CTxcVRvm/7Qw8HfwAPBIkmcZPYnvq6oN8yn5JN8AbgGuT7IMfBF4C1ze89h3Qktq4zuhJbUxQJLaGCBJbQyQpDYGSFIbAySpjQGS1MYASWrz3ylH/h0Xoo/iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1440x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's check a few predictions and their different values\n",
    "i_multiplier = 0\n",
    "num_rows = 3\n",
    "num_cols = 2\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(5*2*num_cols, 5*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_pred(prediction_probabilities=predictions,\n",
    "            labels=val_labels,\n",
    "            images=val_images,\n",
    "            n=i+i_multiplier)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_pred_conf(prediction_probabilities=predictions,\n",
    "                labels=val_labels,\n",
    "                n=i+i_multiplier)\n",
    "plt.tight_layout(h_pad=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e6d5f",
   "metadata": {},
   "source": [
    "## Saving and reloading a model\n",
    "After training a model, it's a good idea to save it. Saving it means you can share it with colleagues, put it in an application and more importantly, won't have to go through the potentially expensive step of retraining it.\n",
    "\n",
    "The format of an entire saved Keras model is h5. So we'll make a function which can take a model as input and utilise the save() method to save it as a h5 file to a specified directory.Saving and reloading a model\n",
    "After training a model, it's a good idea to save it. Saving it means you can share it with colleagues, put it in an application and more importantly, won't have to go through the potentially expensive step of retraining it.\n",
    "\n",
    "The format of an entire saved Keras model is h5. So we'll make a function which can take a model as input and utilise the save() method to save it as a h5 file to a specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fbc5df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, suffix=None):\n",
    "  \"\"\"\n",
    "  Saves a given model in a models directory and appends a suffix (str)\n",
    "  for clarity and reuse.\n",
    "  \"\"\"\n",
    "  # Create model directory with current time\n",
    "  modeldir = os.path.join(\"drive/My Drive/Data/models\",\n",
    "                          datetime.datetime.now().strftime(\"%Y%m%d-%H%M%s\"))\n",
    "  model_path = modeldir + \"-\" + suffix + \".h5\" # save format of model\n",
    "  print(f\"Saving model to: {model_path}...\")\n",
    "  model.save(model_path)\n",
    "  return model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ed511",
   "metadata": {},
   "source": [
    "If we've got a saved model, we'd like to load it, let's create a function which can take a model path and use the tf.keras.models.load_model() function to load it into the notebook.\n",
    "\n",
    "Because we're using a component from TensorFlow Hub (hub.KerasLayer) we'll have to pass this as a parameter to the custom_objects parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f61c6eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "  \"\"\"\n",
    "  Loads a saved model from a specified path.\n",
    "  \"\"\"\n",
    "  print(f\"Loading saved model from: {model_path}\")\n",
    "  model = tf.keras.models.load_model(model_path,\n",
    "                                     custom_objects={\"KerasLayer\":hub.KerasLayer})\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "89308998",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2557905412.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save our model trained on 1000 images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"1000-images-Adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save our model trained on 1000 images\n",
    "save_model(model, suffix=\"1000-images-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "45a6b59c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_20216/3189442155.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\George\\AppData\\Local\\Temp/ipykernel_20216/3189442155.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    model_1000_images = load_model('drive/My Drive/Data/models/20200131-02551580439347-1000-i\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Load our model trained on 1000 images\n",
    "model_1000_images = load_model('drive/My Drive/Data/models/20200131-02551580439347-1000-i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ec9b73",
   "metadata": {},
   "source": [
    "Compare the two models (the original one and loaded one). We can do so easily using the evaluate() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e1fec67",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2675417421.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate the pre-saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the pre-saved model\n",
    "model.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "150cf2ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1000_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3420369481.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Evaluate the loaded model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel_1000_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'model_1000_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the loaded model\n",
    "model_1000_images.evaluate(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc719420",
   "metadata": {},
   "source": [
    "## Training a model (on the full data)\n",
    "Now we know our model works on a subset of the data, we can start to move forward with training one on the full data.\n",
    "\n",
    "Above, we saved all of the training filepaths to X and all of the training labels to y. Let's check them out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1993d1d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/4275896858.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Remind ourselves of the size of the full dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Remind ourselves of the size of the full dataset\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ed8c01",
   "metadata": {},
   "source": [
    "There we go! We've got over 10,000 images and labels in our training set.\n",
    "\n",
    "Before we can train a model on these, we'll have to turn them into a data batch.\n",
    "\n",
    "The beautiful thing is, we can use our create_data_batches() function from above which also preprocesses our images for us (thank you past us for writing a helpful function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a53ef95",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/938559648.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Turn full training data in a data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfull_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Turn full training data in a data batch\n",
    "full_data = create_data_batches(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6d2e96ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1208854212.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Instantiate a new model for training on the full dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfull_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate a new model for training on the full dataset\n",
    "full_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a0bb628",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3557636304.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# TensorBoard callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mfull_model_tensorboard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tensorboard_callback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Early stopping callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/1735571345.py\u001b[0m in \u001b[0;36mcreate_tensorboard_callback\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                         \u001b[1;31m# Make it so the logs get tracked whenever we run an experiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                         datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n\u001b[1;32m----> 9\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Create full model callbacks\n",
    "\n",
    "# TensorBoard callback\n",
    "full_model_tensorboard = create_tensorboard_callback()\n",
    "\n",
    "# Early stopping callback\n",
    "# Note: No validation set when training on all the data, therefore can't monitor validation accruacy\n",
    "full_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"accuracy\",\n",
    "                                                             patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d5df513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir drive/My\\ Drive/Data/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc11c07b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2903634181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the full model to the full training data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m full_model.fit(x=full_data,\n\u001b[0m\u001b[0;32m      3\u001b[0m                \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                callbacks=[full_model_tensorboard, \n\u001b[0;32m      5\u001b[0m                           full_model_early_stopping])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'full_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Fit the full model to the full training data\n",
    "full_model.fit(x=full_data,\n",
    "               epochs=NUM_EPOCHS,\n",
    "               callbacks=[full_model_tensorboard, \n",
    "                          full_model_early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c37d5ec",
   "metadata": {},
   "source": [
    "## Saving and reloading the full model\n",
    "Even on a GPU, our full model took a while to train. So it's a good idea to save it.\n",
    "\n",
    "We can do so using our save_model() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae60655b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3097220296.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save model to file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"all-images-Adam\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'full_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Save model to file\n",
    "save_model(full_model, suffix=\"all-images-Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "160f8222",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (Temp/ipykernel_20216/1969088080.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\George\\AppData\\Local\\Temp/ipykernel_20216/1969088080.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    loaded_full_model = load_model('drive/My Drive/Data/models/20200131-03111580440309-all-im\u001b[0m\n\u001b[1;37m                                                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "# Load in the full model\n",
    "loaded_full_model = load_model('drive/My Drive/Data/models/20200131-03111580440309-all-im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5289962",
   "metadata": {},
   "source": [
    "## Making predictions on the test dataset\n",
    "Since our model has been trained on images in the form of Tensor batches, to make predictions on the test data, we'll have to get it into the same format.\n",
    "\n",
    "Luckily we created create_data_batches() earlier which can take a list of filenames as input and convert them into Tensor batches.\n",
    "\n",
    "To make predictions on the test data, we'll:\n",
    "\n",
    "Get the test image filenames.\n",
    "Convert the filenames into test data batches using create_data_batches() and setting the test_data parameter to True (since there are no labels with the test images).\n",
    "Make a predictions array by passing the test data batches to the predict() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "403f5b62",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/test/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2466395316.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load test image filenames (since we're using os.listdir(), these already have .jpg)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"drive/My Drive/Data/test/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtest_filenames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_filenames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/test/'"
     ]
    }
   ],
   "source": [
    "# Load test image filenames (since we're using os.listdir(), these already have .jpg)\n",
    "test_path = \"drive/My Drive/Data/test/\"\n",
    "test_filenames = [test_path + fname for fname in os.listdir(test_path)]\n",
    "\n",
    "test_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c391cf7e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2607030165.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# How many test images are there?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_filenames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# How many test images are there?\n",
    "len(test_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5bd31492",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_filenames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3553832756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create test data batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_filenames' is not defined"
     ]
    }
   ],
   "source": [
    "# Create test data batch\n",
    "test_data = create_data_batches(test_filenames, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b5f243a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_full_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3801820522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions on test data batch using the loaded full model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m test_predictions = loaded_full_model.predict(test_data,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                              verbose=1)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_full_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data batch using the loaded full model\n",
    "test_predictions = loaded_full_model.predict(test_data,\n",
    "                                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ad0e1c5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2055257098.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Check out the test predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Check out the test predictions\n",
    "test_predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63090280",
   "metadata": {},
   "source": [
    "## Preparing test dataset predictions for Kaggle\n",
    "Looking at the Kaggle sample submission, it looks like they want the models output probabilities each for label along with the image ID's.\n",
    "\n",
    "To get the data in this format, we'll:\n",
    "\n",
    "Create a pandas DataFrame with an ID column as well as a column for each dog breed.\n",
    "Add data to the ID column by extracting the test image ID's from their filepaths.\n",
    "Add data (the prediction probabilities) to each of the dog breed columns using the unique_breeds list and the test_predictions list.\n",
    "Export the DataFrame as a CSV to submit it to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b844d9bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unique_breeds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3910026889.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Create pandas DataFrame with empty columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unique_breeds' is not defined"
     ]
    }
   ],
   "source": [
    "# Create pandas DataFrame with empty columns\n",
    "preds_df = pd.DataFrame(columns=[\"id\"] + list(unique_breeds))\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "14da9c57",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/test/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/722243359.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Append test image ID's to predictions DataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"drive/My Drive/Data/test/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpreds_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mpreds_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/test/'"
     ]
    }
   ],
   "source": [
    "# Append test image ID's to predictions DataFrame\n",
    "test_path = \"drive/My Drive/Data/test/\"\n",
    "preds_df[\"id\"] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e30bb918",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2178082824.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Add the prediction probabilities to each dog breed column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munique_breeds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpreds_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "# Add the prediction probabilities to each dog breed column\n",
    "preds_df[list(unique_breeds)] = test_predictions\n",
    "preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05d67073",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preds_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3612370897.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m preds_df.to_csv(\"drive/My Drive/Data/full_submission_1_mobilienetV2_adam.csv\",\n\u001b[0m\u001b[0;32m      2\u001b[0m                  index=False)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preds_df' is not defined"
     ]
    }
   ],
   "source": [
    "preds_df.to_csv(\"drive/My Drive/Data/full_submission_1_mobilienetV2_adam.csv\",\n",
    "                 index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07173a8f",
   "metadata": {},
   "source": [
    "## Making predictions on custom images\n",
    "It's great being able to make predictions on a test dataset already provided for us.\n",
    "\n",
    "But how could we use our model on our own images?\n",
    "\n",
    "The premise remains, if we want to make predictions on our own custom images, we have to pass them to the model in the same format the model was trained on.\n",
    "\n",
    "To do so, we'll:\n",
    "\n",
    "Get the filepaths of our own images.\n",
    "Turn the filepaths into data batches using create_data_batches(). And since our custom images won't have labels, we set the test_data parameter to True.\n",
    "Pass the custom image data batch to our model's predict() method.\n",
    "Convert the prediction output probabilities to prediction labels.\n",
    "Compare the predicted labels to the custom images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d8de6ea5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/dogs/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2003636856.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get custom image filepaths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcustom_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"drive/My Drive/Data/dogs/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcustom_image_paths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcustom_path\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'drive/My Drive/Data/dogs/'"
     ]
    }
   ],
   "source": [
    "# Get custom image filepaths\n",
    "custom_path = \"drive/My Drive/Data/dogs/\"\n",
    "custom_image_paths = [custom_path + fname for fname in os.listdir(custom_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "707e589e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_image_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/2573347011.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Turn custom image into batch (set to test data because there are no labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcustom_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_data_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_image_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_image_paths' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Turn custom image into batch (set to test data because there are no labels)\n",
    "custom_data = create_data_batches(custom_image_paths, test_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e37f3d21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaded_full_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3112957045.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Make predictions on the custom data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcustom_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloaded_full_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'loaded_full_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Make predictions on the custom data\n",
    "custom_preds = loaded_full_model.predict(custom_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3a72c3fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/569363362.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get custom image prediction labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcustom_pred_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mget_pred_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_preds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcustom_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mcustom_pred_labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_preds' is not defined"
     ]
    }
   ],
   "source": [
    "# Get custom image prediction labels\n",
    "custom_pred_labels = [get_pred_label(custom_preds[i]) for i in range(len(custom_preds))]\n",
    "custom_pred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "83cc5805",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20216/3361292006.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcustom_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Loop through unbatched data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcustom_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m   \u001b[0mcustom_images\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'custom_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Get custom images (our unbatchify() function won't work since there aren't labels)\n",
    "custom_images = []\n",
    "# Loop through unbatched data\n",
    "for image in custom_data.unbatch().as_numpy_iterator():\n",
    "  custom_images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "511f6289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check custom image predictions\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, image in enumerate(custom_images):\n",
    "  plt.subplot(1, 3, i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.title(custom_pred_labels[i])\n",
    "  plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3df0ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
